{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topmost\n",
    "from topmost.data import download_dataset\n",
    "from topmost.preprocessing import Preprocessing\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "device = \"cuda\" # or \"cpu\"\n",
    "dataset_dir = \"/export/usuarios_ml4ds/lbartolome/Datasets/CORDIS/models_preproc/iter_0/topmost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import gensim.downloader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/export/usuarios_ml4ds/lbartolome/Datasets/CORDIS/models_preproc/iter_0/topmost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess raw data\n",
    "preprocessing = Preprocessing(vocab_size=10000)\n",
    "\n",
    "rst = preprocessing.preprocess_jsonlist(dataset_dir=dataset_dir,label_name=\"label\")\n",
    "\n",
    "preprocessing.save(dataset_dir, **rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  52460\n",
      "test_size:  13116\n",
      "vocab_size:  10000\n",
      "average length: 74.651\n"
     ]
    }
   ],
   "source": [
    "dataset = topmost.data.BasicDataset(dataset_dir, read_labels=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "# model = topmost.models.SawETM(vocab_size=dataset.vocab_size, num_topics_list=[10, 50, 200], device=device)\n",
    "model = topmost.models.HyperMiner(vocab_size=dataset.vocab_size, num_topics_list=[10, 50, 200], device=device)\n",
    "#model = topmost.models.TraCo(dataset.vocab_size, num_topics_list=[10, 50, 200])\n",
    "model = model.to(device)\n",
    "\n",
    "# create a trainer\n",
    "trainer = topmost.trainers.HierarchicalTrainer(model, dataset)\n",
    "# train the model\n",
    "top_words, train_theta = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCC': -0.1204091331866122,\n",
       " 'PCD': 0.9680000000000001,\n",
       " 'Sibling_TD': 0.9986666666666666,\n",
       " 'PnCD': 0.9998518518518519}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/export/usuarios_ml4ds/lbartolome/Repos/my_repos/UserInLoopHTM/data/models/traco/trained_model_iter_1.pkl\", \"rb\") as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "results = loaded_data[\"hierarchy_quality_results\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Evaluate ####################################\n",
    "import json\n",
    "import numpy as np\n",
    "from topmost import evaluations\n",
    "\n",
    "# get theta (doc-topic distributions)\n",
    "train_theta, test_theta = trainer.export_theta()\n",
    "\n",
    "# compute topic coherence\n",
    "# refer to https://github.com/BobXWu/ECRTM\n",
    "\n",
    "# compute topic diversity\n",
    "TD = evaluations.multiaspect_topic_diversity(top_words)\n",
    "print(f\"TD: {TD}\")\n",
    "\n",
    "# evaluate clustering\n",
    "#results = evaluations.hierarchical_clustering(test_theta, dataset.test_labels)\n",
    "print(dict(results))\n",
    "\n",
    "# evaluate classification\n",
    "results = evaluations.hierarchical_classification(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\n",
    "print(dict(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate quality of topic hierarchy\n",
    "beta_list = trainer.get_beta()\n",
    "phi_list = trainer.get_phi()\n",
    "annoated_top_words = trainer.get_top_words(annotation=True)\n",
    "reference_bow = np.concatenate((dataset.train_bow, dataset.test_bow), axis=0) # or reference_bow = train_bow\n",
    "results, topic_hierarchy = evaluations.hierarchy_quality(dataset.vocab, reference_bow, annoated_top_words, beta_list, phi_list)\n",
    "\n",
    "print(json.dumps(topic_hierarchy, indent=4))\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prueba",
   "language": "python",
   "name": "prueba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
